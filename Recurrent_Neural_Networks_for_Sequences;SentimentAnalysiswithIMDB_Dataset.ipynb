{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recurrent_Neural_Networks_for_Sequences;SentimentAnalysiswithIMDB_Dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNHoFmFY01WJQSNeumYfMzS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/austinmula/ML---Classes/blob/master/Recurrent_Neural_Networks_for_Sequences%3BSentimentAnalysiswithIMDB_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4JvM8Mvi2NP"
      },
      "source": [
        "# Dataset to be used - Sentiment analysis(Feeling) - binary problems\n",
        "# Positive or Negative"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhILSQFojGwC"
      },
      "source": [
        "# Recurrent Neural Networks\n",
        "\n",
        "- Process a sequence of data (-time series or text in sentiment)\n",
        "- **Recurrent** - contains loops\n",
        "- output of one given layer is the input of the same layer in the next step\n",
        "\n",
        "Time Step\n",
        "-  The next point in time series \n",
        "- Next work in a sequence of words for a text sequence\n",
        "- RNN takes into account the relationship among earlier and later data in a sequence \n",
        "- loops in RNNs help them to learn relationships among the data in the sequence. Good -- on its own has positive sentiment Not good has a negative sentiment,, Not is earlier in the sequence RNNs do consider the relationships among earlier and later data in the sequence. Here the words that determine sentiment are adjacent. But when considering text's meaning there can be many words to consider and an arbitrary number of words between them.\n",
        "\n",
        "Long Short-Term Memory (LSTM)-- layer that makes the neural network recurrent.\n",
        "\n",
        "- Text mining\n",
        "- responding to Q with predicted best answers\n",
        "- inter language translation\n",
        "- Automated video closed captioning -speech recognition\n",
        "- speech analysis\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlGC9c2KnGCf"
      },
      "source": [
        "# Load the Data\n",
        "\n",
        "The data has 25 000 training sample and 25000 testind sample. The output is either 1(posistive) and 0(negative)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOZYuwKZnVjw"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO_-S9lknqce"
      },
      "source": [
        "- The dataset contains over 88000 unique words \n",
        "- We should then specify how much to use\n",
        "- Due to system memory limitation, we will use 10000. Make use of a TPU OR GPU\n",
        "- More data means you get better models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhQwuq-IncGs"
      },
      "source": [
        "number_of_words = 10000"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Q4MJrSqv-8"
      },
      "source": [
        "# Theres an issue with how tensorflow keras and numpy work"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHguVSFUrL7U"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuICF_urrPLa"
      },
      "source": [
        "np_load_old=np.load"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOu6brRFrTuG"
      },
      "source": [
        "# Modify the default parameters of np.load"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rE9rm0SrZiQ"
      },
      "source": [
        "np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-2Zsb4zsATQ"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=number_of_words)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJMM02_nsgci"
      },
      "source": [
        "np.load=np_load_old"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NZ2jCljtNYS",
        "outputId": "b5fbd319-5a66-41c6-e98c-fcd9e2756849"
      },
      "source": [
        "# Data Exploration\n",
        "x_test.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWd-7YUmuSYL",
        "outputId": "0e8054a7-7c46-49d9-bee4-d3d9a3ba0fa7"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIrttVUiufMZ",
        "outputId": "05f150e3-f766-4149-d146-55c6906e3d1a"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu5JHGUkuj6D",
        "outputId": "d02ea062-0028-4886-fe72-33252a151344"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA5s2hIiu3eb"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2tP_uuyvVAo",
        "outputId": "808ff24e-7c38-414c-a853-95408760b9bd"
      },
      "source": [
        "%pprint # toggle better printing so that elements do not display vertically"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretty printing has been turned ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-n1uwi4u2P9",
        "outputId": "dcee733a-497a-421e-cd34-094e21e037cb"
      },
      "source": [
        "x_train[200]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 9,\n",
              " 6,\n",
              " 227,\n",
              " 196,\n",
              " 241,\n",
              " 634,\n",
              " 891,\n",
              " 234,\n",
              " 21,\n",
              " 12,\n",
              " 69,\n",
              " 6,\n",
              " 6,\n",
              " 176,\n",
              " 7,\n",
              " 4,\n",
              " 804,\n",
              " 4658,\n",
              " 2999,\n",
              " 667,\n",
              " 11,\n",
              " 12,\n",
              " 11,\n",
              " 85,\n",
              " 715,\n",
              " 6,\n",
              " 176,\n",
              " 7,\n",
              " 1565,\n",
              " 8,\n",
              " 1108,\n",
              " 10,\n",
              " 10,\n",
              " 12,\n",
              " 16,\n",
              " 1844,\n",
              " 2,\n",
              " 33,\n",
              " 211,\n",
              " 21,\n",
              " 69,\n",
              " 49,\n",
              " 2009,\n",
              " 905,\n",
              " 388,\n",
              " 99,\n",
              " 2,\n",
              " 125,\n",
              " 34,\n",
              " 6,\n",
              " 2,\n",
              " 1274,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 7,\n",
              " 4,\n",
              " 22,\n",
              " 15,\n",
              " 16,\n",
              " 6424,\n",
              " 8,\n",
              " 650,\n",
              " 1069,\n",
              " 14,\n",
              " 22,\n",
              " 9,\n",
              " 44,\n",
              " 4609,\n",
              " 153,\n",
              " 154,\n",
              " 4,\n",
              " 318,\n",
              " 302,\n",
              " 1051,\n",
              " 23,\n",
              " 14,\n",
              " 22,\n",
              " 122,\n",
              " 6,\n",
              " 2093,\n",
              " 292,\n",
              " 10,\n",
              " 10,\n",
              " 723,\n",
              " 8721,\n",
              " 5,\n",
              " 2,\n",
              " 9728,\n",
              " 71,\n",
              " 1344,\n",
              " 1576,\n",
              " 156,\n",
              " 11,\n",
              " 68,\n",
              " 251,\n",
              " 5,\n",
              " 36,\n",
              " 92,\n",
              " 4363,\n",
              " 133,\n",
              " 199,\n",
              " 743,\n",
              " 976,\n",
              " 354,\n",
              " 4,\n",
              " 64,\n",
              " 439,\n",
              " 9,\n",
              " 3059,\n",
              " 17,\n",
              " 32,\n",
              " 4,\n",
              " 2,\n",
              " 26,\n",
              " 256,\n",
              " 34,\n",
              " 2,\n",
              " 5,\n",
              " 49,\n",
              " 7,\n",
              " 98,\n",
              " 40,\n",
              " 2345,\n",
              " 9844,\n",
              " 43,\n",
              " 92,\n",
              " 168,\n",
              " 147,\n",
              " 474,\n",
              " 40,\n",
              " 8,\n",
              " 67,\n",
              " 6,\n",
              " 796,\n",
              " 97,\n",
              " 7,\n",
              " 14,\n",
              " 20,\n",
              " 19,\n",
              " 32,\n",
              " 2188,\n",
              " 156,\n",
              " 24,\n",
              " 18,\n",
              " 6090,\n",
              " 1007,\n",
              " 21,\n",
              " 8,\n",
              " 331,\n",
              " 97,\n",
              " 4,\n",
              " 65,\n",
              " 168,\n",
              " 5,\n",
              " 481,\n",
              " 53,\n",
              " 3084]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l67FPBSfxnoU"
      },
      "source": [
        "To view the original text you need to know the word to which each number corresponds to. The Keras dictionary maps words to their indices. Each word's value is its frequency. Eg. 1 is frequently occuring in that dataset\n",
        "\n",
        "-- Training and testing data have an offset of 3. Most freq occuring word has a value of 4. (1+3). Values 0,1,2 are reserved words.\n",
        "\n",
        "0 - padding --all the train/test must have some dimension. Some reviews may need to be handled with a 0 and some shortened.\n",
        "\n",
        "Start of the sequence - 1 -- a token used by keras internally for learning purposes.\n",
        "\n",
        "Unknown word - 2 -- Words that are not loaded. load_data func uses 2 for words with freq rankings > the number of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe8H0DyguqWZ"
      },
      "source": [
        "word_to_index=imdb.get_word_index()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-GJIlFVxrIz",
        "outputId": "19c1a729-bc6a-4b1b-9e28-69cced6c668e"
      },
      "source": [
        "word_to_index['great']"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuJCVdgkxuk4",
        "outputId": "b011730a-d85a-4e62-9556-91e8b21755c9"
      },
      "source": [
        "word_to_index['wood']"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2134"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfM5E3f-xy9t",
        "outputId": "9008eb00-6d8b-40b2-bc29-fdd857dacad6"
      },
      "source": [
        "word_to_index['the']"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBpOWcr8x1wZ"
      },
      "source": [
        "#lets create a mapping for checking words by frequency rating \n",
        "index_to_word={index: word for (word, index) in word_to_index.items()}"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8eYxKs-x_E4",
        "outputId": "72f2804d-70b5-4565-817e-60ebd9409fe2"
      },
      "source": [
        "# We then pick the top 60 most frequently used words whose key is one\n",
        "[index_to_word[i] for i in range(1, 61)]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'and',\n",
              " 'a',\n",
              " 'of',\n",
              " 'to',\n",
              " 'is',\n",
              " 'br',\n",
              " 'in',\n",
              " 'it',\n",
              " 'i',\n",
              " 'this',\n",
              " 'that',\n",
              " 'was',\n",
              " 'as',\n",
              " 'for',\n",
              " 'with',\n",
              " 'movie',\n",
              " 'but',\n",
              " 'film',\n",
              " 'on',\n",
              " 'not',\n",
              " 'you',\n",
              " 'are',\n",
              " 'his',\n",
              " 'have',\n",
              " 'he',\n",
              " 'be',\n",
              " 'one',\n",
              " 'all',\n",
              " 'at',\n",
              " 'by',\n",
              " 'an',\n",
              " 'they',\n",
              " 'who',\n",
              " 'so',\n",
              " 'from',\n",
              " 'like',\n",
              " 'her',\n",
              " 'or',\n",
              " 'just',\n",
              " 'about',\n",
              " \"it's\",\n",
              " 'out',\n",
              " 'has',\n",
              " 'if',\n",
              " 'some',\n",
              " 'there',\n",
              " 'what',\n",
              " 'good',\n",
              " 'more',\n",
              " 'when',\n",
              " 'very',\n",
              " 'up',\n",
              " 'no',\n",
              " 'time',\n",
              " 'she',\n",
              " 'even',\n",
              " 'my',\n",
              " 'would',\n",
              " 'which']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "nH25ukWvyKcZ",
        "outputId": "37447b47-48d4-4c79-d5f3-c640d357c41b"
      },
      "source": [
        "' '.join([index_to_word.get(i-3, '?') for i in x_train[1]])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"? big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal ? the hair is big lots of boobs ? men wear those cut ? shirts that show off their ? sickening that men actually wore them and the music is just ? trash that plays over and over again in almost every scene there is trashy music boobs and ? taking away bodies and the gym still doesn't close for ? all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\""
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKerU47iynue",
        "outputId": "c050f212-f0f6-4e7b-89c4-12faeef37796"
      },
      "source": [
        "y_train[1]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W3C8sMOyxOr"
      },
      "source": [
        "# Data Preparation"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-7ojKxuy8bh"
      },
      "source": [
        "words_per_review = 200"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2v_k2Q1zAnE"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0YSh5RAzGvy"
      },
      "source": [
        "x_train = pad_sequences(x_train, maxlen=words_per_review)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrdB61JRzNoy",
        "outputId": "02e92224-54e1-4e0b-f49d-3d18f83d6a7b"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz8eKaasznkb",
        "outputId": "1e079998-3d76-4992-fa08-7a9772662efb"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   5,   25,  100,   43,  838,  112,   50,  670,    2,    9,   35,\n",
              "        480,  284,    5,  150,    4,  172,  112,  167,    2,  336,  385,\n",
              "         39,    4,  172, 4536, 1111,   17,  546,   38,   13,  447,    4,\n",
              "        192,   50,   16,    6,  147, 2025,   19,   14,   22,    4, 1920,\n",
              "       4613,  469,    4,   22,   71,   87,   12,   16,   43,  530,   38,\n",
              "         76,   15,   13, 1247,    4,   22,   17,  515,   17,   12,   16,\n",
              "        626,   18,    2,    5,   62,  386,   12,    8,  316,    8,  106,\n",
              "          5,    4, 2223, 5244,   16,  480,   66, 3785,   33,    4,  130,\n",
              "         12,   16,   38,  619,    5,   25,  124,   51,   36,  135,   48,\n",
              "         25, 1415,   33,    6,   22,   12,  215,   28,   77,   52,    5,\n",
              "         14,  407,   16,   82,    2,    8,    4,  107,  117, 5952,   15,\n",
              "        256,    4,    2,    7, 3766,    5,  723,   36,   71,   43,  530,\n",
              "        476,   26,  400,  317,   46,    7,    4,    2, 1029,   13,  104,\n",
              "         88,    4,  381,   15,  297,   98,   32, 2071,   56,   26,  141,\n",
              "          6,  194, 7486,   18,    4,  226,   22,   21,  134,  476,   26,\n",
              "        480,    5,  144,   30, 5535,   18,   51,   36,   28,  224,   92,\n",
              "         25,  104,    4,  226,   65,   16,   38, 1334,   88,   12,   16,\n",
              "        283,    5,   16, 4472,  113,  103,   32,   15,   16, 5345,   19,\n",
              "        178,   32], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2FfZtPNzqEN",
        "outputId": "44db8567-705b-428e-cb20-e975ab8f93b6"
      },
      "source": [
        "x_train.ndim"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owH5mo6QztZh"
      },
      "source": [
        "x_test = pad_sequences(x_test, maxlen=words_per_review)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWpljDpxz7WC",
        "outputId": "97912c1f-01e5-44b7-901d-cae503572dd9"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H4Ot6Abz-GY"
      },
      "source": [
        "# Splitting the data into validation and test data"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QKtZxGn0FbY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}